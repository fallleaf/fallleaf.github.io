<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>AOC on Reading,Thinking And Writing</title>
        <link>https://blog.fallleaf.net/tags/aoc/</link>
        <description>Recent content in AOC on Reading,Thinking And Writing</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>红旗下的蛋</copyright>
        <lastBuildDate>Sat, 13 Sep 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.fallleaf.net/tags/aoc/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>GPU之后的算力革命?微软新架构让AI推理与金融优化&#34;一机双飞&#34;</title>
        <link>https://blog.fallleaf.net/p/tech-microsoft-architecture-ai-financial-revolution/</link>
        <pubDate>Sat, 13 Sep 2025 00:00:00 +0000</pubDate>
        
        <guid>https://blog.fallleaf.net/p/tech-microsoft-architecture-ai-financial-revolution/</guid>
        <description>&lt;img src="https://blog.fallleaf.net/p/tech-microsoft-architecture-ai-financial-revolution/cover.jpg" alt="Featured image of post GPU之后的算力革命?微软新架构让AI推理与金融优化&#34;一机双飞&#34;" /&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;你有没有想过——&lt;/strong&gt;
&lt;strong&gt;未来训练一个大模型，可能不再需要耗电如“小电站”的GPU集群？&lt;/strong&gt;
&lt;strong&gt;处理一笔复杂的跨国金融结算，可能不需要数小时的服务器运算？&lt;/strong&gt;
&lt;strong&gt;甚至做一次MRI扫描，时间能从30分钟缩短到几分钟？&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这一切，正被一项刚刚登上《自然》杂志的研究悄然实现。&lt;/p&gt;
&lt;p&gt;由微软研究院、剑桥大学与巴克莱银行联合团队开发的模拟光学计算机（Analog Optical Computer, AOC），首次实现同一硬件平台高效运行AI推理与组合优化两大任务，在理论能效上比当前最强GPU高出100倍以上。&lt;/p&gt;
&lt;p&gt;这不是PPT概念，而是实打实的物理原型机，已通过MNIST图像分类、医学影像重建、金融交易结算等真实场景验证。&lt;/p&gt;
&lt;h2 id=&#34;为什么我们需要一台非数字的计算机&#34;&gt;为什么我们需要一台“非数字”的计算机？
&lt;/h2&gt;&lt;p&gt;今天的人工智能，几乎全靠“数字芯片”驱动。但问题来了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;内存墙：数据在CPU/GPU和显存间来回搬运，消耗了超过80%的能耗。&lt;/li&gt;
&lt;li&gt;功耗爆炸：训练GPT-4级别的模型，一次电费可达数万美元。&lt;/li&gt;
&lt;li&gt;算力瓶颈：摩尔定律逼近极限，传统芯片再难靠“堆晶体管”提升效率。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;于是，科学家们开始“回归模拟”——模拟计算不把数据变成0和1，而是用连续的电压/光强直接表达信息，天然适合矩阵乘法、迭代求解这类AI和优化核心操作。&lt;/p&gt;
&lt;p&gt;但过去的问题是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;光学擅长并行乘法，但不会做tanh激活函数；&lt;/li&gt;
&lt;li&gt;模拟电路擅长非线性，但没法高速传输海量数据；&lt;/li&gt;
&lt;li&gt;两者结合时，必须经过昂贵的“数模转换”，吃掉大部分节能优势。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;AOC的颠覆性突破，就在于彻底消除了这个“转换环节”。&lt;/p&gt;
&lt;h2 id=&#34;aoc是如何工作的光与电的永动舞&#34;&gt;AOC是如何工作的？光与电的“永动舞”
&lt;/h2&gt;&lt;p&gt;想象一个闭环系统，每20纳秒完成一次“思考”：&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;组件&lt;/th&gt;
          &lt;th&gt;功能&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;微LED阵列&lt;/td&gt;
          &lt;td&gt;将输入变量编码为光强（比如：图像像素、交易金额）&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;空间光调制器（SLM）&lt;/td&gt;
          &lt;td&gt;存储权重矩阵，像“光的乘法表”一样，让光信号自动完成并行矩阵乘法&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;光电探测器&lt;/td&gt;
          &lt;td&gt;将光信号转为电压，送入模拟电路&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;模拟电子电路&lt;/td&gt;
          &lt;td&gt;执行tanh非线性、减法、退火、动量更新 —— 完全在连续域中进行&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;整个过程没有ADC/DAC，没有中间缓存，所有计算都在“模拟态”中循环迭代，直到系统稳定在一个“固定点”——这正是深度平衡模型（DEQ）和优化问题的数学本质！&lt;/p&gt;
&lt;p&gt;关键优势：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;抗噪：固定点像引力中心，噪声越扰，越被拉回正确解&lt;/li&gt;
&lt;li&gt;无内存墙：无需存储中间层激活值&lt;/li&gt;
&lt;li&gt;动态深度：推理时间由收敛速度决定，不是预设层数&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;真实场景验证它到底能干什么&#34;&gt;真实场景验证：它到底能干什么？
&lt;/h2&gt;&lt;p&gt;论文用四大案例证明AOC不是“玩具”：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;AI推理：图像分类 &amp;amp; 非线性回归&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;在MNIST和Fashion-MNIST上，准确率达95%–98%&lt;/li&gt;
&lt;li&gt;成功拟合高斯、正弦曲线，误差低至0.00375（MSE）&lt;/li&gt;
&lt;li&gt;全部训练在数字孪生模型（AOC-DT）中完成，部署到硬件无需重新校准&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;关键：它跑的是深度平衡模型（DEQ），一种“无限深”的递归网络，传统数字芯片跑得慢、耗电高，而AOC天生匹配。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;医疗：MRI加速重建&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;传统MRI需采集大量数据才能成像，耗时长。&lt;/p&gt;
&lt;p&gt;AOC采用L0范数压缩感知（理论上最优但极难计算），仅用62.5%的数据，就重建出接近原图的清晰脑部切片，误差降低近10倍！&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;金融：解决NP难的交易结算&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;全球每日有数万亿美元交易待清算，如何最大化“一次性结清”的交易数？这是典型的NP难问题。&lt;/p&gt;
&lt;p&gt;AOC将问题建模为混合二次无约束优化（QUMO），支持二进制 + 连续变量（如：是否结算、结算金额），在7步内找到全局最优解，全程模拟运算，无任何数字后处理。&lt;/p&gt;
&lt;p&gt;对比：量子计算机在类似问题上成功率仅40–60%，而AOC达到100%。&lt;/p&gt;
&lt;h2 id=&#34;性能有多强别被百倍吓到我们说清楚&#34;&gt;性能有多强？别被“百倍”吓到，我们说清楚
&lt;/h2&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;指标&lt;/th&gt;
          &lt;th&gt;当前原型&lt;/th&gt;
          &lt;th&gt;理论预测(扩展后)&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;权重数量&lt;/td&gt;
          &lt;td&gt;4,096（通过时间复用实现）&lt;/td&gt;
          &lt;td&gt;0.1亿 – 20亿&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;单次迭代&lt;/td&gt;
          &lt;td&gt;180纳秒&lt;/td&gt;
          &lt;td&gt;同样&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;能效&lt;/td&gt;
          &lt;td&gt;原型功耗高（驱动电路为主）&lt;/td&gt;
          &lt;td&gt;500 TOPS/W（8位精度）&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;对比GPU&lt;/td&gt;
          &lt;td&gt;H100约4.5 TOPS/W&lt;/td&gt;
          &lt;td&gt;理论能效超百倍&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;重要澄清：
“百倍能效”是理论推演值，基于未来模块化扩展架构；
当前原型是桌面级设备（16×16变量），用于验证原理；
真正价值不在“快”，而在“省” —— 一旦规模化，每瓦特算力将远超硅基芯片。&lt;/p&gt;
&lt;h2 id=&#34;未来之路十亿权重不是梦&#34;&gt;未来之路：十亿权重，不是梦
&lt;/h2&gt;&lt;p&gt;AOC的可扩展性设计非常聪明：&lt;/p&gt;
&lt;p&gt;每个模块：微LED + SLM + 光电探测器 + 模拟电路 → 尺寸仅约4 cm³
利用三维光学结构，实现光路高效复用（非平面光计算）
使用成熟消费级技术（手机里也有微LED、SLM）
多模块并联，即可扩展至百亿级权重&lt;/p&gt;
&lt;p&gt;专家判断：若成功量产，将成为继GPU之后，下一代AI算力的核心候选架构之一。&lt;/p&gt;
&lt;h2 id=&#34;为什么这是一场范式革命&#34;&gt;为什么这是一场“范式革命”？
&lt;/h2&gt;&lt;p&gt;我们过去追求的是：“更快的数字芯片”。&lt;/p&gt;
&lt;p&gt;而AOC告诉我们：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“更聪明的物理系统”才是未来。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;它不是在“模仿人脑”，而是在用光和电的物理规律，直接求解数学问题。
它不依赖冯·诺依曼架构，不被内存墙束缚，不因数模转换浪费能源。&lt;/p&gt;
&lt;p&gt;这就像从“手写算盘”进化到“机械计算器”——不是更快地拨珠子，而是换了一套计算逻辑。&lt;/p&gt;
&lt;h2 id=&#34;结语实验室的光终将照亮现实&#34;&gt;结语：实验室的光，终将照亮现实
&lt;/h2&gt;&lt;p&gt;AOC目前仍是原型，距离商用还有工程挑战：热管理、三维集成、大规模制造……
但它首次证明了：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一类硬件，可同时服务AI与优化；
模拟+光学，能超越数字芯片的能效天花板；
算法与硬件协同设计，能带来数量级突破。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;当我们在为大模型的电费发愁，为自动驾驶的算力焦虑时，微软与剑桥的这支团队，已经点亮了一条通往“绿色AI”的新路径。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这不是“下一个十年”，
而是正在发生的，下一场计算革命的序章。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;论文原文：(&lt;a class=&#34;link&#34; href=&#34;https://doi.org/10.1038/s41586-025-09430-z&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://doi.org/10.1038/s41586-025-09430-z&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;本文初稿使用AI协助编写，虽经人工校对，水平有限，请谅解。&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
